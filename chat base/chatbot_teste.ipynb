{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62081487-8b70-4d41-ac22-db99732eafae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk # pip install nltk\n",
    "import re # pip install re\n",
    "import string\n",
    "import spacy #pip install spacy\n",
    "import random\n",
    "\n",
    "from spacy.lang.pt.examples import sentences\n",
    "from nltk.chat.util import Chat, reflections\n",
    "from bs4 import BeautifulSoup # pip install bs4\n",
    "from urllib.request import urlopen\n",
    "from random import choice, randint\n",
    "from sklearn.metrics.pairwise import cosine_similarity # pip install scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # pip install scikit-learn\n",
    "\n",
    "# pip install lxml => erro de parser\n",
    "# python -m spacy download pt_core_news_sm => erro de linguagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e16d13a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_url = urlopen(\"https://pt.wikipedia.org/wiki/Intelig%C3%AAncia_artificial\").read()\n",
    "txt_html = BeautifulSoup(txt_url, 'lxml').find_all('p')\n",
    "texto_pag_web = ''\n",
    "for i in txt_html:\n",
    "  texto_pag_web += i.text.lower()\n",
    "lista_sentencas = nltk.sent_tokenize(texto_pag_web)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b156bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"pt_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5244b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# palavras que o modelo irá ignorar\n",
    "stop_words = spacy.lang.pt.stop_words.STOP_WORDS\n",
    "# pontuações que o modelo irá ignorar\n",
    "stop_punct = string.punctuation\n",
    "\n",
    "def preprocessamento(texto): #preparando o texto para ser processado pelo spacy\n",
    "  # tirar urls\n",
    "  texto = re.sub(r\"https?://[A-Za-z0-9./]+\",' ',texto)\n",
    "  # tirar espaços em branco\n",
    "  texto = re.sub(r\" +\", ' ',texto)\n",
    "  # tirar radical (lematização)\n",
    "  documento = nlp(texto)\n",
    "  lista = []\n",
    "  for token in documento:\n",
    "    lista.append(token.lemma_)\n",
    "  lista = [palavra for palavra in lista if palavra not in stop_words and palavra not in stop_punct]\n",
    "  lista = ' '.join([str(elemento) for elemento in lista if not elemento.isdigit()])\n",
    "  return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74647cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar as sentenças que serão pré-processadas pela função em uma lista\n",
    "lista_sentencas_preprocessada = []\n",
    "for i in range(len(lista_sentencas)):\n",
    "  lista_sentencas_preprocessada.append(preprocessamento(lista_sentencas[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "641003bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "textos_boas_vindas_entrada = ('hey', 'olá', 'opa', 'oi', 'eae')\n",
    "textos_boas_vindas_respostas = ('hey', 'olá', 'opa', 'oi', 'bem-vindo', 'como você está?')\n",
    "textos_saida = ('sair','tchau','exit','esc')\n",
    "\n",
    "def responder_saudacao(texto):\n",
    "  for palavra in texto.split():\n",
    "    if palavra.lower() in textos_boas_vindas_entrada:\n",
    "      return random.choice(textos_boas_vindas_respostas)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df08d988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def responder(texto_usuario):\n",
    "  resposta_chatbot = ''\n",
    "  lista_sentencas_preprocessada.append(texto_usuario)\n",
    "\n",
    "  tfidf = TfidfVectorizer()\n",
    "  palavras_vetorizadas = tfidf.fit_transform(lista_sentencas_preprocessada)\n",
    "\n",
    "  similaridade = cosine_similarity(palavras_vetorizadas[-1], palavras_vetorizadas)\n",
    "\n",
    "  indice_sentenca = similaridade.argsort()[0][-2]\n",
    "  vetor_similar = similaridade.flatten()\n",
    "  vetor_similar.sort()\n",
    "  vetor_encontrado = vetor_similar[-2]\n",
    "\n",
    "  if (vetor_encontrado == 0):\n",
    "    resposta_chatbot = resposta_chatbot + 'Desculpe, mas não entendi!'\n",
    "    return resposta_chatbot\n",
    "  else:\n",
    "    resposta_chatbot = resposta_chatbot + lista_sentencas[indice_sentenca]\n",
    "    return resposta_chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d564695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olá, sou um chatbot e vou responder perguntas sobre inteligência artificial: \n",
      "Usuário: \n",
      "Chatbot: \n",
      "opa\n",
      "\n",
      "Usuário: \n",
      "Chatbot: \n",
      "outra definição de inteligência artificial é a inteligência que surge de um \"dispositivo artificial\".\n",
      "\n",
      "Usuário: \n"
     ]
    }
   ],
   "source": [
    "print('Olá, sou um chatbot e vou responder perguntas sobre inteligência artificial: ')\n",
    "while True:\n",
    "  print('Usuário: ')\n",
    "  texto_usuario = input().lower()\n",
    "  if texto_usuario not in textos_saida:\n",
    "    if responder_saudacao(texto_usuario) != None:\n",
    "      print('Chatbot: ')\n",
    "      print(responder_saudacao(texto_usuario))\n",
    "      print()\n",
    "    else:\n",
    "      print('Chatbot: ')\n",
    "      print(responder(preprocessamento(texto_usuario)))\n",
    "      print()\n",
    "      lista_sentencas_preprocessada.remove(preprocessamento(texto_usuario))\n",
    "  else:\n",
    "    print('Chatbot: Até breve!')\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
